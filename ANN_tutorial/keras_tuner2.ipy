# -*- coding: utf-8 -*-
"""
Created on Fri Apr 29 20:46:59 2022

@author: user
"""


#import libraries
from sklearn.model_selection import train_test_split
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pickle

df=pd.read_csv("C:/Users/user/Desktop/DL_tutorial/ANN_tutorial/churn_modellin.csv")

# splitiing data
x=df.iloc[:,3:13]
y=df.iloc[:,13]

# converting categprical features to dummie geography and gender
geo=pd.get_dummies(x["Geography"],drop_first=True)
gender=pd.get_dummies(x["Gender"],drop_first=True)

 
#concatenate data_frame
X=pd.concat([x,geo,gender],axis=1)
# drop unnecssary columns
X=X.drop(columns=["Geography","Gender"],axis=1)

#split into test and train
x_train, x_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=1)
  
#feature scaling
## Note:feature scaling is important in deep learning cos of 
##product of weight and input since large magnitude of input can take a longer
from sklearn.preprocessing import StandardScaler
sc=StandardScaler()
x_train=sc.fit_transform(x_train)
x_test=sc.transform(x_test)

# perform hyperparameters tuning
from keras.wrappers.scikit_learn import KerasClassifier
from sklearn.model_selection import GridSearchCV

from keras.models import Sequential
from keras.layers import Dense,Activation,Embedding,Flatten,LeakyReLU,BatchNormalization,Dropout
from keras.activations import relu,sigmoid


def create_model(layers,activation):
    model=Sequential()
    for i,nodes in enumerate(layers):
        if i==0:
            model.add(Dense(nodes,input_dim=x_train.shape[1]))
            model.add(Activation(activation))
            model.add(Dropout(0.3))
        else:
            model.add(Dense(nodes))
            model.add(Activation(activation))
            model.add(Dropout(0.3))
        model.add(Dense(1,kernel_initializer="glorot_uniform",activation="sigmoid"))
    
        model.compile(optimizer="Adam",loss="binary_crossentropy",metrics=["accuracy"])
        return model
model=KerasClassifier(build_fn=create_model,verbose=0)

layers=[[20],[40,20],[45,30,15]]
activations=["sigmoid","relu"]
param_grid=dict(layers=layers,activation=activations,batch_size=[120,250],epochs=[30])
grid=GridSearchCV(estimator=model,param_grid=param_grid,cv=5)

grid_result=grid.fit(x_train,y_train)

# model best result
print(grid_result.best_score_,grid_result.best_params_)
pred_y=grid.predict(x_test)
pred_y=(pred_y > 0.5)

from sklearn.metrics import confusion_matrix,accuracy_score
confm=confusion_matrix(pred_y,y_test)
score=accuracy_score(pred_y,y_test)










